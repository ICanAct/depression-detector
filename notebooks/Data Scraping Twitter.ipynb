{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q snscrape\n",
    "#!pip install -q pandas\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters to query twitter\n",
    "max_limit_tweets = 21000 #1mil tweets will take about 22 hours\n",
    "language = 'en' #only tweets with english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scrape based on passed in query -> once finished, save all to csv\n",
    "def scrape_tweets(query):\n",
    "    start_time = time.time()\n",
    "\n",
    "    tweets = []\n",
    "    count = 0\n",
    "\n",
    "    for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "        tweets.append(tweet)\n",
    "        count += 1\n",
    "        \n",
    "        if count >= max_limit_tweets:\n",
    "            break\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape data and add labels to it based on the hashtag\n",
    "\n",
    "#anxiety\n",
    "anxiety_hashtags = ['#anxietyhelp', '#anxietyattack', '#anxietydisorder', '#anxietysupport', '#fuckanxiety', '#anxietyawareness']\n",
    "\n",
    "#depression\n",
    "depression_hashtags = ['#depressionhelp', '#fuckdepression', '#depresion', '#depressionrecovery']\n",
    "\n",
    "#bipolar\n",
    "bipolar_hashtags = ['#bipolarhelp', '#bipolarawareness', '#bipolardisorder', '#bipolarrecovery', '#bippolar', '#bipolar1', 'bipolar2', '#bpd']\n",
    "\n",
    "#ptsd\n",
    "ptsd_hashtags = ['#ptsdhelp', '#ptsdawareness', '#ptsdrecovery', '#ptsdsupport', '#ptsdtherapy', '#cptsd', '#fuckptsd', 'ptsdsucks']\n",
    "\n",
    "#eating disorders\n",
    "eating_disorders_hashtags = ['#eatingdisorder', '#eatingdisorderhelp', '#anorexiahelp', '#bulimiahelp', '#ednos', '#ednoshelp', '#edrecovery', '#edawareness']\n",
    "\n",
    "#neutral data\n",
    "neutral_hashtags = ['#music', '#food', '#basketball', '#science', '#nature']\n",
    "\n",
    "labels = {'anxiety': 0, 'depression': 1, 'bipolar': 2, 'ptsd': 3, 'eatingdisorders': 4, 'neutral': 5}\n",
    "query_hashtags = {'anxiety': anxiety_hashtags, 'depression': depression_hashtags, 'bipolar': bipolar_hashtags, 'ptsd': ptsd_hashtags, 'eatingdisorders': eating_disorders_hashtags, 'neutral': neutral_hashtags}\n",
    "\n",
    "queries = []\n",
    "for label,hashtags in query_hashtags.items():\n",
    "    curr_query = ''\n",
    "    for hashtag in hashtags:\n",
    "        curr_query = curr_query + hashtag + ' OR '\n",
    "    curr_query = curr_query[:-4] #remove last OR\n",
    "    queries.append(curr_query)\n",
    "\n",
    "for idx, query in enumerate(queries):\n",
    "    #filter replies, media and URLs\n",
    "    queries[idx] = ('({}) lang:{} -filter:links -filter:replies').format(query, language)\n",
    "\n",
    "#adjust each query to prevent tweets with the following hashtags: '#mentalhealth', '#anxiety', '#depression', '#bipolar', '#ptsd', '#anorexia', '#bulimia'\n",
    "#to prevent duplicates from expert base + to ensure higher quality tweets (by ignoring most obvious hashtags)\n",
    "for idx, query in enumerate(queries):\n",
    "    queries[idx] = query + ' -#mentalhealth -#anxiety -#depression -#bipolar -#ptsd -#anorexia -#bulimia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: anxiety 21000\n",
      "Done: depression 21000\n",
      "Done: bipolar 21000\n",
      "Done: ptsd 17745\n",
      "Done: eatingdisorders 21000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"neutral_tweets = scrape_tweets(queries[5])\\nneutral_df = pd.DataFrame(neutral_tweets)\\nneutral_df['label'] = labels['neutral']\\nneutral_df.to_csv('neutral_tweets.csv', index=False)\\nprint('Done: neutral')\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape tweets\n",
    "anxiety_tweets = scrape_tweets(queries[0])\n",
    "anxiety_df = pd.DataFrame(anxiety_tweets)\n",
    "anxiety_df['label'] = labels['anxiety']\n",
    "anxiety_df.to_csv('anxiety_tweets.csv', index=False)\n",
    "print('Done: anxiety', len(anxiety_df))\n",
    "\n",
    "depression_tweets = scrape_tweets(queries[1])\n",
    "depression_df = pd.DataFrame(depression_tweets)\n",
    "depression_df['label'] = labels['depression']\n",
    "depression_df.to_csv('depression_tweets.csv', index=False)\n",
    "print('Done: depression', len(depression_df))\n",
    "\n",
    "bipolar_tweets = scrape_tweets(queries[2])\n",
    "bipolar_df = pd.DataFrame(bipolar_tweets)\n",
    "bipolar_df['label'] = labels['bipolar']\n",
    "bipolar_df.to_csv('bipolar_tweets.csv', index=False)\n",
    "print('Done: bipolar', len(bipolar_df))\n",
    "\n",
    "ptsd_tweets = scrape_tweets(queries[3])\n",
    "ptsd_df = pd.DataFrame(ptsd_tweets)\n",
    "ptsd_df['label'] = labels['ptsd']\n",
    "ptsd_df.to_csv('ptsd_tweets.csv', index=False)\n",
    "print('Done: ptsd', len(ptsd_df))\n",
    "\n",
    "eatingdisorders_tweets = scrape_tweets(queries[4])\n",
    "eatingdisorders_df = pd.DataFrame(eatingdisorders_tweets)\n",
    "eatingdisorders_df['label'] = labels['eatingdisorders']\n",
    "eatingdisorders_df.to_csv('eatingdisorders_tweets.csv', index=False)\n",
    "print('Done: eatingdisorders', len(eatingdisorders_df))\n",
    "\n",
    "'''neutral_tweets = scrape_tweets(queries[5])\n",
    "neutral_df = pd.DataFrame(neutral_tweets)\n",
    "neutral_df['label'] = labels['neutral']\n",
    "neutral_df.to_csv('neutral_tweets.csv', index=False)\n",
    "print('Done: neutral', len(neutral_df))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21000\n",
      "1    21000\n",
      "2    21000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#read in all csvs\n",
    "anxiety_df = pd.read_csv('anxiety_tweets.csv')\n",
    "depression_df = pd.read_csv('depression_tweets.csv')\n",
    "#bipolar_df = pd.read_csv('bipolar_tweets.csv')\n",
    "#ptsd_df = pd.read_csv('ptsd_tweets.csv')\n",
    "#eatingdisorders_df = pd.read_csv('eatingdisorders_tweets.csv')\n",
    "neutral_df = pd.read_csv('neutral_tweets.csv')\n",
    "\n",
    "#drop duplicates\n",
    "anxiety_df = anxiety_df.drop_duplicates()\n",
    "depression_df = depression_df.drop_duplicates()\n",
    "#bipolar_df = bipolar_df.drop_duplicates()\n",
    "#ptsd_df = ptsd_df.drop_duplicates()\n",
    "#eatingdisorders_df = eatingdisorders_df.drop_duplicates()\n",
    "neutral_df = neutral_df.drop_duplicates()\n",
    "\n",
    "#change neutral label to 3\n",
    "neutral_df['label'] = 2\n",
    "\n",
    "#combine all dataframes and save to csv\n",
    "combined_df = pd.concat([anxiety_df, depression_df, neutral_df])\n",
    "#print number of tweets per label\n",
    "print(combined_df['label'].value_counts())\n",
    "combined_df.to_csv('all_train_test_twitter.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Pre-Processing Steps:\n",
    "- Remove newlines\n",
    "- Remove URLs\n",
    "- Remove punctuation (for twitter only)\n",
    "- Replace all instances of 3 or more letters with 2 letters\n",
    "- Remove all instances of 3 or more repeated subsequent words (ex: \"I love love love love you\")\n",
    "- Remove html tags\n",
    "- Remove non-ascii characters\n",
    "- Handling Bullet Points or similar\n",
    "- Replace numbers with \\<num\\> token\n",
    "\n",
    "\n",
    "Twitter Specific Pre-Processing Steps:\n",
    "- Remove RT\n",
    "- Remove @mentions and usernames for privacy\n",
    "- Remove hashtags (remove hashtags (both symbol and respective word) for hashtags used in querying) (keep hashtags not used for querying (remove only the hashtag symbol but keep the word))\n",
    "\n",
    "Reddit Specific Pre-Processing Steps:\n",
    "- Only keep english text (twitter data was already filtered to english, reddit wasn't)\n",
    "- Remove user mentions\n",
    "- Remove \"Removed Posts\" Posts\n",
    "\n",
    "\n",
    "Processing Steps we also can/need to do for Non-Bert Models:\n",
    "- Remove stopwords (except for maybe \"not\" and \"no\")\n",
    "- Handling Clitics\n",
    "- Handling Ellipses\n",
    "- Having a minimum word frequency and replacing words that occur less than that with \\<unk\\> token\n",
    "- Replace emojis/emoticons with \\<emoji\\> token or remove them\n",
    "\n",
    "Post-Processing for Bert Step 2 and other model\n",
    "- Only use posts/tweets that pass a pre-trained sentiment classifier\n",
    "- Remove tweets that do not have a minumum number of replies/likes/retweets/followers/etc\n",
    "- Remove posts that do not have a minimum number of score (upvotes - downvotes) or number of comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

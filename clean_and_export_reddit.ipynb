{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function estimation using neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_tweets import normalizeTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode A: read in a csv file\n",
    "os.chdir(\"C:/Users/Gary/Desktop/Year 1 Sem 2/CS5246 Text Mining/Group Project/depression-detector/data/\")\n",
    "file = \"reddit_all.csv\"\n",
    "df_orig = pd.read_csv(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mode B: read in a folder of csv files\n",
    "# os.chdir(\"C:/Users/Gary/Desktop/Year 1 Sem 2/CS5246 Text Mining/Group Project/depression-detector/data/CSV Files Per Label\")\n",
    "\n",
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "# # combine all files in the list\n",
    "# df_orig = pd.concat([pd.read_csv(f) for f in all_filenames ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some    questions    regarding    anxiety    a...</td>\n",
       "      <td>I    am    not    diagnosed    as    having   ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2023-02-21    18:45:35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i    feel    so    angry    and    jealous    ...</td>\n",
       "      <td>so,    i’m    17,    i’ve    had    anxiety   ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2023-02-21    18:45:23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do    you    guys    think    it's    ok    th...</td>\n",
       "      <td>Because    of    agoraphobia    I    haven't  ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2023-02-21    18:37:51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How    to    get    through    performance    ...</td>\n",
       "      <td>I    (29M)    just    got    dumped    by    m...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2023-02-21    18:35:17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My    friend    just    got    jumped.</td>\n",
       "      <td>He's    alr    now    but    I    don't    kno...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2023-02-21    18:31:29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Some    questions    regarding    anxiety    a...   \n",
       "1  i    feel    so    angry    and    jealous    ...   \n",
       "2  do    you    guys    think    it's    ok    th...   \n",
       "3  How    to    get    through    performance    ...   \n",
       "4             My    friend    just    got    jumped.   \n",
       "\n",
       "                                            selftext subreddit  \\\n",
       "0  I    am    not    diagnosed    as    having   ...   Anxiety   \n",
       "1  so,    i’m    17,    i’ve    had    anxiety   ...   Anxiety   \n",
       "2  Because    of    agoraphobia    I    haven't  ...   Anxiety   \n",
       "3  I    (29M)    just    got    dumped    by    m...   Anxiety   \n",
       "4  He's    alr    now    but    I    don't    kno...   Anxiety   \n",
       "\n",
       "                     date  num_comments  score  label  \n",
       "0  2023-02-21    18:45:35             0      1      0  \n",
       "1  2023-02-21    18:45:23             0      1      0  \n",
       "2  2023-02-21    18:37:51             0      1      0  \n",
       "3  2023-02-21    18:35:17             0      1      0  \n",
       "4  2023-02-21    18:31:29             0      1      0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show first 5 rows\n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134181 entries, 0 to 134180\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   title         134181 non-null  object\n",
      " 1   selftext      127204 non-null  object\n",
      " 2   subreddit     134181 non-null  object\n",
      " 3   date          134181 non-null  object\n",
      " 4   num_comments  134181 non-null  int64 \n",
      " 5   score         134181 non-null  int64 \n",
      " 6   label         134181 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_orig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace selftext with title if selftext is [removed], [deleted], empty,nan, or as per title\n",
    "df_orig['selftext'] = df_orig['selftext'].replace(np.nan, '', regex=True)\n",
    "df_orig['selftext'] = np.where(df_orig['selftext'].isin(['[removed]', '[deleted]', '', 'as per title']), df_orig['title'], df_orig['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I    am    not    diagnosed    as    having   ...\n",
       "1    so,    i’m    17,    i’ve    had    anxiety   ...\n",
       "2    Because    of    agoraphobia    I    haven't  ...\n",
       "3    I    (29M)    just    got    dumped    by    m...\n",
       "4    He's    alr    now    but    I    don't    kno...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig['selftext'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 134181 entries, 0 to 134180\n",
      "Series name: selftext\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "134181 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#Extract only rawContent column for use\n",
    "df= df_orig['selftext']\n",
    "\n",
    "df.rename(\"cleaned\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         I    am    not    diagnosed    as    having   ...\n",
       "1         so,    i’m    17,    i’ve    had    anxiety   ...\n",
       "2         Because    of    agoraphobia    I    haven't  ...\n",
       "3         I    (29M)    just    got    dumped    by    m...\n",
       "4         He's    alr    now    but    I    don't    kno...\n",
       "                                ...                        \n",
       "134176    i    always    considered    ODing    but    b...\n",
       "134177    I    don't    know    how    to    celebrate  ...\n",
       "134178        I    took    some    pills    of    mine  ...\n",
       "134179    my    psychotic    episodes    are    getting ...\n",
       "134180    its    almost    everyday    i    feel    like...\n",
       "Name: selftext, Length: 134181, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #un-labelled data\n",
    "\n",
    "# #Apply normalizeTweet function to each row\n",
    "# df = df.apply(normalizeTweet)\n",
    "\n",
    "# #show first 5 rows of cleaned data\n",
    "# display(df.head())\n",
    "\n",
    "# #append original data for comparison\n",
    "# df = pd.concat([df_orig['selftext'],df], axis=1)\n",
    "\n",
    "# #rename columns\n",
    "# df.columns = ['originalreddit', 'cleanedreddit']\n",
    "# display(df.head())\n",
    "\n",
    "# #export to csv\n",
    "# df.to_csv('cleaned_'+file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I am not diagnosed as having anxiety but i hav...\n",
       "1    so im seventeen i have had anxiety from a very...\n",
       "2    because of agoraphobia I havent worked and don...\n",
       "3    I 29m just got dumped by my last girlfriend be...\n",
       "4    hes alr now but I dont know what to do we call...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalreddit</th>\n",
       "      <th>cleanedreddit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I    am    not    diagnosed    as    having   ...</td>\n",
       "      <td>I am not diagnosed as having anxiety but i hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so,    i’m    17,    i’ve    had    anxiety   ...</td>\n",
       "      <td>so im seventeen i have had anxiety from a very...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because    of    agoraphobia    I    haven't  ...</td>\n",
       "      <td>because of agoraphobia I havent worked and don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I    (29M)    just    got    dumped    by    m...</td>\n",
       "      <td>I 29m just got dumped by my last girlfriend be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's    alr    now    but    I    don't    kno...</td>\n",
       "      <td>hes alr now but I dont know what to do we call...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      originalreddit  \\\n",
       "0  I    am    not    diagnosed    as    having   ...   \n",
       "1  so,    i’m    17,    i’ve    had    anxiety   ...   \n",
       "2  Because    of    agoraphobia    I    haven't  ...   \n",
       "3  I    (29M)    just    got    dumped    by    m...   \n",
       "4  He's    alr    now    but    I    don't    kno...   \n",
       "\n",
       "                                       cleanedreddit  label  \n",
       "0  I am not diagnosed as having anxiety but i hav...      0  \n",
       "1  so im seventeen i have had anxiety from a very...      0  \n",
       "2  because of agoraphobia I havent worked and don...      0  \n",
       "3  I 29m just got dumped by my last girlfriend be...      0  \n",
       "4  hes alr now but I dont know what to do we call...      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#labelled data\n",
    "\n",
    "#Apply normalizeTweet function to each row\n",
    "df = df.apply(normalizeTweet)\n",
    "\n",
    "#show first 5 rows of cleaned data\n",
    "display(df.head())\n",
    "\n",
    "#append original data for comparison\n",
    "df = pd.concat([df_orig['selftext'],df,df_orig['label']], axis=1)\n",
    "\n",
    "#rename columns\n",
    "df.columns = ['originalreddit', 'cleanedreddit', 'label']\n",
    "display(df.head())\n",
    "\n",
    "#export to csv\n",
    "df.to_csv('cleaned_'+file, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Pre-Processing Steps:\n",
    "- lowercase all\n",
    "- Remove newlines\n",
    "- Remove URLs\n",
    "- Remove punctuation (for twitter only)\n",
    "- Replace 2 or more spaces with 1 space\n",
    "- Replace all instances of 3 or more letters with 2 letters\n",
    "- Remove all instances of 3 or more repeated subsequent words (ex: \"I love love love love you\")\n",
    "- Remove html tags (don't think there is any)\n",
    "- Remove non-ascii characters\n",
    "- Handling Bullet Points or similar (lists, tables etc.)\n",
    "- Replace numbers with \\<num\\> token\n",
    "- Detect foreign language and remove the entire item\n",
    "\n",
    "\n",
    "Twitter Specific Pre-Processing Steps:\n",
    "- Remove RT\n",
    "- Remove @mentions and usernames for privacy\n",
    "- Remove hashtags (remove hashtags (both symbol and respective word) for hashtags used in querying) (keep hashtags not used for querying (remove only the hashtag symbol but keep the word))\n",
    "\n",
    "Reddit Specific Pre-Processing Steps:\n",
    "- Only keep english text (twitter data was already filtered to english, reddit wasn't)\n",
    "- Remove user mentions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
